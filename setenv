# What prefix should be used for your job names (useful for repetitive package names). End with a dot.
export CLASS_PREFIX=nl.utwente.bigdata.
# Number of computers to use
export EXECUTORS=10
# Number of cores to use per executor
export CORES=4
# Amount of memory per computer or executor (node)
export EXECUTOR_MEM=4g
# Amount of memory on the driver (the node that coordinates the job)
export DRIVER_MEM=2g

# Some admin variables
export PROJECT_HOME=$PWD
export LIBJARS=$(echo $PROJECT_HOME/target/lib/*.jar | tr ' ' ',')
export HADOOP_CONF_DIR=/etc/hadoop/conf
export USER=$(whoami)
export SPARK_DIR=/usr/lib/spark/bin
# run tool with yarn-resource manager choosing a worker as the driver
function runTool() {
        name=$1
        shift
        $SPARK_DIR/spark-submit --class ${CLASS_PREFIX}$name \
            --name $name \
            --master yarn-cluster \
            --num-executors $EXECUTORS \
            --driver-memory $DRIVER_MEM \
            --executor-memory $EXECUTOR_MEM \
            --executor-cores $CORES \
            --queue $USER \
            target/ctit-spark*.jar \
            $@
}
# run tool with the local machine being the driver program.
function runToolClient() {
        name=$1
        shift
        $SPARK_DIR/spark-submit --class ${CLASS_PREFIX}$name \
            --master yarn-client \
            --num-executors $EXECUTORS \
            --driver-memory $DRIVER_MEM \
            --executor-memory $EXECUTOR_MEM \
            --executor-cores $CORES \
            --queue $USER \
            target/ctit-spark*.jar \
            $@
}
# create a shell
function runShell() {
        $SPARK_DIR/spark-shell \
            --master yarn-client \
            --num-executors $EXECUTORS \
            --driver-memory $DRIVER_MEM \
            --executor-memory $EXECUTOR_MEM \
            --executor-cores $CORES \
            --conf spark.ui.port=4050 \
            --queue ${USER} \
            $@ 
}
