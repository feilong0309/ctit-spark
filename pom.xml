<?xml version="1.0" encoding="UTF-8"?>
<!-- ~ Licensed to the Apache Software Foundation (ASF) under one or more 
	~ contributor license agreements. See the NOTICE file distributed with ~ 
	this work for additional information regarding copyright ownership. ~ The 
	ASF licenses this file to You under the Apache License, Version 2.0 ~ (the 
	"License"); you may not use this file except in compliance with ~ the License. 
	You may obtain a copy of the License at ~ ~ http://www.apache.org/licenses/LICENSE-2.0 
	~ ~ Unless required by applicable law or agreed to in writing, software ~ 
	distributed under the License is distributed on an "AS IS" BASIS, ~ WITHOUT 
	WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. ~ See the 
	License for the specific language governing permissions and ~ limitations 
	under the License. -->

<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>
	<groupId>nl.utwente.bigdata</groupId>
	<artifactId>ctit-spark</artifactId>
	<packaging>jar</packaging>
	<version>1.5.1</version>
	<name>CTIT Spark Code</name>
	<url>http://spark.apache.org/</url>

	<properties>
		<sbt.project.name>examples</sbt.project.name>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
		<project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>
		<akka.group>com.typesafe.akka</akka.group>
		<akka.version>2.3.11</akka.version>
		<java.version>1.7</java.version>
		<maven.version>3.3.3</maven.version>
		<sbt.project.name>spark</sbt.project.name>
		<mesos.version>0.21.1</mesos.version>
		<mesos.classifier>shaded-protobuf</mesos.classifier>
		<slf4j.version>1.7.10</slf4j.version>
		<log4j.version>1.2.17</log4j.version>
		<hadoop.version>2.2.0</hadoop.version>
		<protobuf.version>2.5.0</protobuf.version>
		<yarn.version>${hadoop.version}</yarn.version>
		<hbase.version>0.98.7-hadoop2</hbase.version>
		<hbase.artifact>hbase</hbase.artifact>
		<flume.version>1.6.0</flume.version>
		<zookeeper.version>3.4.5</zookeeper.version>
		<curator.version>2.4.0</curator.version>
		<hive.group>org.spark-project.hive</hive.group>
		<!-- Version used in Maven Hive dependency -->
		<hive.version>1.2.1.spark</hive.version>
		<!-- Version used for internal directory structure -->
		<hive.version.short>1.2.1</hive.version.short>
		<derby.version>10.10.1.1</derby.version>
		<parquet.version>1.7.0</parquet.version>
		<hive.parquet.version>1.6.0</hive.parquet.version>
		<jblas.version>1.2.4</jblas.version>
		<jetty.version>8.1.14.v20131031</jetty.version>
		<orbit.version>3.0.0.v201112011016</orbit.version>
		<chill.version>0.5.0</chill.version>
		<ivy.version>2.4.0</ivy.version>
		<oro.version>2.0.8</oro.version>
		<codahale.metrics.version>3.1.2</codahale.metrics.version>
		<avro.version>1.7.7</avro.version>
		<avro.mapred.classifier>hadoop2</avro.mapred.classifier>
		<jets3t.version>0.7.1</jets3t.version>
		<aws.java.sdk.version>1.9.16</aws.java.sdk.version>
		<aws.kinesis.client.version>1.3.0</aws.kinesis.client.version>
		<!-- org.apache.httpcomponents/httpclient -->
		<commons.httpclient.version>4.3.2</commons.httpclient.version>
		<!-- commons-httpclient/commons-httpclient -->
		<httpclient.classic.version>3.1</httpclient.classic.version>
		<commons.math3.version>3.4.1</commons.math3.version>
		<scala.version>2.10</scala.version>
		<scala.binary.version>2.10</scala.binary.version>
		<jline.version>${scala.version}</jline.version>
		<jline.groupid>org.scala-lang</jline.groupid>
		<codehaus.jackson.version>1.9.13</codehaus.jackson.version>
		<fasterxml.jackson.version>2.4.4</fasterxml.jackson.version>
		<snappy.version>1.1.1.7</snappy.version>
		<netlib.java.version>1.1.2</netlib.java.version>
		<calcite.version>1.2.0-incubating</calcite.version>
		<commons-codec.version>1.10</commons-codec.version>
		<!-- org.apache.commons/commons-lang/ -->
		<commons-lang2.version>2.6</commons-lang2.version>
		<!-- org.apache.commons/commons-lang3/ -->
		<commons-lang3.version>3.3.2</commons-lang3.version>
		<datanucleus-core.version>3.2.10</datanucleus-core.version>
		<janino.version>2.7.8</janino.version>
		<jersey.version>1.9</jersey.version>
		<joda.version>2.5</joda.version>
		<jodd.version>3.5.2</jodd.version>
		<jsr305.version>1.3.9</jsr305.version>
		<libthrift.version>0.9.2</libthrift.version>

		<test.java.home>${java.home}</test.java.home>
		<test.exclude.tags></test.exclude.tags>

		<!-- Dependency scopes that can be overridden by enabling certain profiles. 
			These profiles are declared in the projects that build assemblies. For other 
			projects the scope should remain as "compile", otherwise they are not available 
			during compilation if the dependency is transivite (e.g. "bagel/" depending 
			on "core/" and needing Hadoop classes in the classpath to compile). -->
		<flume.deps.scope>compile</flume.deps.scope>
		<hadoop.deps.scope>compile</hadoop.deps.scope>
		<hbase.deps.scope>compile</hbase.deps.scope>
		<hive.deps.scope>compile</hive.deps.scope>
		<parquet.deps.scope>compile</parquet.deps.scope>
		<parquet.test.deps.scope>test</parquet.test.deps.scope>

		<!-- Overridable test home. So that you can call individual pom files directly 
			without things breaking. -->
		<spark.test.home>${session.executionRootDirectory}</spark.test.home>

		<PermGen>64m</PermGen>
		<MaxPermGen>512m</MaxPermGen>
		<CodeCacheSize>512m</CodeCacheSize>
	</properties>
	<repositories>
		<repository>
			<id>scala-tools.org</id>
			<name>Scala-tools Maven2 Repository</name>
			<url>http://scala-tools.org/repo-releases</url>
		</repository>
	</repositories>
	<pluginRepositories>
		<pluginRepository>
			<id>scala-tools.org</id>
			<name>Scala-tools Maven2 Repository</name>
			<url>http://scala-tools.org/repo-releases</url>
		</pluginRepository>
	</pluginRepositories>

	<dependencies>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-core_${scala.binary.version}</artifactId>
			<version>${project.version}</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming_${scala.binary.version}</artifactId>
			<version>${project.version}</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-mllib_${scala.binary.version}</artifactId>
			<version>${project.version}</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-bagel_${scala.binary.version}</artifactId>
			<version>${project.version}</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-hive_${scala.binary.version}</artifactId>
			<version>${project.version}</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-graphx_${scala.binary.version}</artifactId>
			<version>${project.version}</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming-twitter_${scala.binary.version}</artifactId>
			<version>${project.version}</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming-flume_${scala.binary.version}</artifactId>
			<version>${project.version}</version>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming-mqtt_${scala.binary.version}</artifactId>
			<version>${project.version}</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming-zeromq_${scala.binary.version}</artifactId>
			<version>${project.version}</version>
			<scope>provided</scope>
			<exclusions>
				<exclusion>
					<groupId>org.spark-project.protobuf</groupId>
					<artifactId>protobuf-java</artifactId>
				</exclusion>
			</exclusions>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming-kafka_${scala.binary.version}</artifactId>
			<version>${project.version}</version>
		</dependency>
		<dependency>
			<groupId>org.apache.hbase</groupId>
			<artifactId>hbase-testing-util</artifactId>
			<version>${hbase.version}</version>
			<scope>${hbase.deps.scope}</scope>
			<exclusions>
				<exclusion>
					<!-- SPARK-4455 -->
					<groupId>org.apache.hbase</groupId>
					<artifactId>hbase-annotations</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.jruby</groupId>
					<artifactId>jruby-complete</artifactId>
				</exclusion>
			</exclusions>
		</dependency>
		<dependency>
			<groupId>org.apache.hbase</groupId>
			<artifactId>hbase-protocol</artifactId>
			<version>${hbase.version}</version>
			<scope>${hbase.deps.scope}</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.hbase</groupId>
			<artifactId>hbase-common</artifactId>
			<version>${hbase.version}</version>
			<scope>${hbase.deps.scope}</scope>
			<exclusions>
				<exclusion>
					<!-- SPARK-4455 -->
					<groupId>org.apache.hbase</groupId>
					<artifactId>hbase-annotations</artifactId>
				</exclusion>
			</exclusions>
		</dependency>
		<dependency>
			<groupId>org.apache.hbase</groupId>
			<artifactId>hbase-client</artifactId>
			<version>${hbase.version}</version>
			<scope>${hbase.deps.scope}</scope>
			<exclusions>
				<exclusion>
					<!-- SPARK-4455 -->
					<groupId>org.apache.hbase</groupId>
					<artifactId>hbase-annotations</artifactId>
				</exclusion>
				<exclusion>
					<groupId>io.netty</groupId>
					<artifactId>netty</artifactId>
				</exclusion>
			</exclusions>
		</dependency>
		<dependency>
			<groupId>org.apache.hbase</groupId>
			<artifactId>hbase-server</artifactId>
			<version>${hbase.version}</version>
			<scope>${hbase.deps.scope}</scope>
			<exclusions>
				<exclusion>
					<!-- SPARK-4455 -->
					<groupId>org.apache.hbase</groupId>
					<artifactId>hbase-annotations</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.hadoop</groupId>
					<artifactId>hadoop-core</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.hadoop</groupId>
					<artifactId>hadoop-client</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.hadoop</groupId>
					<artifactId>hadoop-mapreduce-client-jobclient</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.hadoop</groupId>
					<artifactId>hadoop-mapreduce-client-core</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.hadoop</groupId>
					<artifactId>hadoop-auth</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.hadoop</groupId>
					<artifactId>hadoop-annotations</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.hadoop</groupId>
					<artifactId>hadoop-hdfs</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.hbase</groupId>
					<artifactId>hbase-hadoop1-compat</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.commons</groupId>
					<artifactId>commons-math</artifactId>
				</exclusion>
				<exclusion>
					<groupId>com.sun.jersey</groupId>
					<artifactId>jersey-core</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.slf4j</groupId>
					<artifactId>slf4j-api</artifactId>
				</exclusion>
				<exclusion>
					<groupId>com.sun.jersey</groupId>
					<artifactId>jersey-server</artifactId>
				</exclusion>
				<exclusion>
					<groupId>com.sun.jersey</groupId>
					<artifactId>jersey-core</artifactId>
				</exclusion>
				<exclusion>
					<groupId>com.sun.jersey</groupId>
					<artifactId>jersey-json</artifactId>
				</exclusion>
				<exclusion>
					<!-- hbase uses v2.4, which is better, but ... -->
					<groupId>commons-io</groupId>
					<artifactId>commons-io</artifactId>
				</exclusion>
			</exclusions>
		</dependency>
		<dependency>
			<groupId>org.apache.hbase</groupId>
			<artifactId>hbase-hadoop-compat</artifactId>
			<version>${hbase.version}</version>
			<scope>${hbase.deps.scope}</scope>
		</dependency>
		<dependency>
			<groupId>edu.umd</groupId>
			<artifactId>cloud9</artifactId>
			<version>2.0.2-SNAPSHOT</version>
		</dependency>
		<dependency>
			<groupId>tl.lin</groupId>
			<artifactId>lintools-datatypes</artifactId>
			<version>1.0.0</version>
		</dependency>
		<dependency>
			<groupId>org.apache.hbase</groupId>
			<artifactId>hbase-hadoop-compat</artifactId>
			<version>${hbase.version}</version>
			<type>test-jar</type>
			<scope>test</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.commons</groupId>
			<artifactId>commons-math3</artifactId>
			<version>3.5</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>com.twitter</groupId>
			<artifactId>algebird-core_${scala.binary.version}</artifactId>
			<version>0.9.0</version>
		</dependency>
		<dependency>
			<groupId>org.apache.cassandra</groupId>
			<artifactId>cassandra-all</artifactId>
			<version>1.2.6</version>
			<exclusions>
				<exclusion>
					<groupId>com.google.guava</groupId>
					<artifactId>guava</artifactId>
				</exclusion>
				<exclusion>
					<groupId>com.googlecode.concurrentlinkedhashmap</groupId>
					<artifactId>concurrentlinkedhashmap-lru</artifactId>
				</exclusion>
				<exclusion>
					<groupId>com.ning</groupId>
					<artifactId>compress-lzf</artifactId>
				</exclusion>
				<exclusion>
					<groupId>commons-cli</groupId>
					<artifactId>commons-cli</artifactId>
				</exclusion>
				<exclusion>
					<groupId>commons-codec</groupId>
					<artifactId>commons-codec</artifactId>
				</exclusion>
				<exclusion>
					<groupId>commons-lang</groupId>
					<artifactId>commons-lang</artifactId>
				</exclusion>
				<exclusion>
					<groupId>commons-logging</groupId>
					<artifactId>commons-logging</artifactId>
				</exclusion>
				<exclusion>
					<groupId>io.netty</groupId>
					<artifactId>netty</artifactId>
				</exclusion>
				<exclusion>
					<groupId>jline</groupId>
					<artifactId>jline</artifactId>
				</exclusion>
				<exclusion>
					<groupId>net.jpountz.lz4</groupId>
					<artifactId>lz4</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.cassandra.deps</groupId>
					<artifactId>avro</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.commons</groupId>
					<artifactId>commons-math3</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.thrift</groupId>
					<artifactId>libthrift</artifactId>
				</exclusion>
			</exclusions>
		</dependency>
		<dependency>
			<groupId>com.github.scopt</groupId>
			<artifactId>scopt_${scala.binary.version}</artifactId>
			<version>3.2.0</version>
		</dependency>
		<dependency>
			<groupId>org.scala-lang</groupId>
			<artifactId>scala-library</artifactId>
			<version>2.10.5</version>
		</dependency>
		<dependency>
			<groupId>com.google.code.findbugs</groupId>
			<artifactId>jsr305</artifactId>
			<version>2.0.2</version>
		</dependency>
	</dependencies>
	<build>
		<plugins>
			<plugin>
				<groupId>org.scala-tools</groupId>
				<artifactId>maven-scala-plugin</artifactId>
				<version>2.11</version>
				<executions>

					<execution>
						<id>compile</id>
						<goals>
							<goal>compile</goal>
						</goals>
						<phase>compile</phase>
					</execution>
					<execution>
						<id>test-compile</id>
						<goals>
							<goal>testCompile</goal>
						</goals>
						<phase>test-compile</phase>
					</execution>
					<execution>
						<phase>process-resources</phase>
						<goals>
							<goal>compile</goal>
						</goals>
					</execution>
				</executions>
			</plugin>
			<plugin>
				<artifactId>maven-compiler-plugin</artifactId>
				<configuration>
					<source>1.5</source>
					<target>1.5</target>
				</configuration>
			</plugin>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-shade-plugin</artifactId>
				<configuration>
					<shadedArtifactAttached>false</shadedArtifactAttached>
					<artifactSet>
						<includes>
							<!-- At a minimum we must include this to force effective pom generation -->
							<include>org.spark-project.spark:unused</include>

							<include>org.eclipse.jetty:jetty-io</include>
							<include>org.eclipse.jetty:jetty-http</include>
							<include>org.eclipse.jetty:jetty-continuation</include>
							<include>org.eclipse.jetty:jetty-servlet</include>
							<include>org.eclipse.jetty:jetty-plus</include>
							<include>org.eclipse.jetty:jetty-security</include>
							<include>org.eclipse.jetty:jetty-util</include>
							<include>org.eclipse.jetty:jetty-server</include>
							<include>tl.lin:lintools-datatypes</include>
							<include>edu.umd:cloud9</include>
							<include>com.google.guava:guava</include>
						</includes>
					</artifactSet>
					<relocations>
						<relocation>
							<pattern>org.eclipse.jetty</pattern>
							<shadedPattern>org.spark-project.jetty</shadedPattern>
							<includes>
								<include>org.eclipse.jetty.**</include>
							</includes>
						</relocation>
						<relocation>
							<pattern>com.google.common</pattern>
							<shadedPattern>org.spark-project.guava</shadedPattern>
							<excludes>
								<!-- These classes cannot be relocated, because the Java API exposes 
									the "Optional" type; the others are referenced by the Optional class. -->
								<exclude>com/google/common/base/Absent*</exclude>
								<exclude>com/google/common/base/Function</exclude>
								<exclude>com/google/common/base/Optional*</exclude>
								<exclude>com/google/common/base/Present*</exclude>
								<exclude>com/google/common/base/Supplier</exclude>
							</excludes>
						</relocation>
					</relocations>
				</configuration>
				<executions>
					<execution>
						<phase>package</phase>
						<goals>
							<goal>shade</goal>
						</goals>
					</execution>
				</executions>
			</plugin>
			<plugin>
				<groupId>org.codehaus.mojo</groupId>
				<artifactId>build-helper-maven-plugin</artifactId>
				<executions>
					<execution>
						<id>add-source</id>
						<phase>generate-sources</phase>
						<goals>
							<goal>add-source</goal>
						</goals>
						<configuration>
							<sources>
								<source>src/main/scala</source>
							</sources>
						</configuration>
					</execution>
					<execution>
						<id>add-test-source</id>
						<phase>generate-sources</phase>
						<goals>
							<goal>add-test-source</goal>
						</goals>
						<configuration>
							<sources>
								<source>src/test/scala</source>
							</sources>
						</configuration>
					</execution>
				</executions>
			</plugin>

			<plugin>
				<groupId>org.scala-tools</groupId>
				<artifactId>maven-scala-plugin</artifactId>

				<executions>
					<execution>
						<id>compile</id>
						<goals>
							<goal>compile</goal>
						</goals>
						<phase>compile</phase>
					</execution>

					<execution>
						<id>test-compile</id>
						<goals>
							<goal>testCompile</goal>
						</goals>
						<phase>test-compile</phase>
					</execution>

					<execution>
						<phase>process-resources</phase>
						<goals>
							<goal>compile</goal>
						</goals>
					</execution>
				</executions>
			</plugin>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-deploy-plugin</artifactId>
				<configuration>
					<skip>true</skip>
				</configuration>
			</plugin>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-install-plugin</artifactId>
				<configuration>
					<skip>true</skip>
				</configuration>
			</plugin>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-compiler-plugin</artifactId>
				<version>3.3</version>
				<configuration>
					<source>1.7</source>
					<target>1.7</target>
				</configuration>
			</plugin>
		</plugins>
	</build>
	<profiles>
		<profile>
			<id>kinesis-asl</id>
			<dependencies>
				<dependency>
					<groupId>org.apache.spark</groupId>
					<artifactId>spark-streaming-kinesis-asl_${scala.binary.version}</artifactId>
					<version>${project.version}</version>
				</dependency>
			</dependencies>
		</profile>

		<!-- Profiles that disable inclusion of certain dependencies. -->
		<profile>
			<id>flume-provided</id>
			<properties>
				<flume.deps.scope>provided</flume.deps.scope>
			</properties>
		</profile>
		<profile>
			<id>hadoop-provided</id>
			<properties>
				<hadoop.deps.scope>provided</hadoop.deps.scope>
			</properties>
		</profile>
		<profile>
			<id>hbase-provided</id>
			<properties>
				<hbase.deps.scope>provided</hbase.deps.scope>
			</properties>
		</profile>
		<profile>
			<id>hive-provided</id>
			<properties>
				<hive.deps.scope>provided</hive.deps.scope>
			</properties>
		</profile>
		<profile>
			<id>parquet-provided</id>
			<properties>
				<parquet.deps.scope>provided</parquet.deps.scope>
			</properties>
		</profile>
	</profiles>
</project>
