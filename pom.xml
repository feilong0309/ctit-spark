<?xml version="1.0" encoding="UTF-8"?>
<!-- ~ Licensed to the Apache Software Foundation (ASF) under one or more 
	~ contributor license agreements. See the NOTICE file distributed with ~ 
	this work for additional information regarding copyright ownership. ~ The 
	ASF licenses this file to You under the Apache License, Version 2.0 ~ (the 
	"License"); you may not use this file except in compliance with ~ the License. 
	You may obtain a copy of the License at ~ ~ http://www.apache.org/licenses/LICENSE-2.0 
	~ ~ Unless required by applicable law or agreed to in writing, software ~ 
	distributed under the License is distributed on an "AS IS" BASIS, ~ WITHOUT 
	WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. ~ See the 
	License for the specific language governing permissions and ~ limitations 
	under the License. -->

<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>
	<groupId>nl.utwente.bigdata</groupId>
	<artifactId>ctit-spark</artifactId>
	<packaging>jar</packaging>
	<version>1.5.1</version>
	<name>CTIT Spark Code</name>
	<url>http://spark.apache.org/</url>

	<properties>
		<sbt.project.name>examples</sbt.project.name>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
		<project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>
		<akka.group>com.typesafe.akka</akka.group>
		<akka.version>2.3.11</akka.version>
		<java.version>1.7</java.version>
		<maven.version>3.3.3</maven.version>
		<sbt.project.name>spark</sbt.project.name>
		<mesos.version>0.21.1</mesos.version>
		<mesos.classifier>shaded-protobuf</mesos.classifier>
		<slf4j.version>1.7.10</slf4j.version>
		<log4j.version>1.2.17</log4j.version>
		<hadoop.version>2.2.0</hadoop.version>
		<protobuf.version>2.5.0</protobuf.version>
		<yarn.version>${hadoop.version}</yarn.version>
		<zookeeper.version>3.4.5</zookeeper.version>
		<curator.version>2.4.0</curator.version>
		<hive.group>org.spark-project.hive</hive.group>
		<!-- Version used in Maven Hive dependency -->
		<hive.version>1.2.1.spark</hive.version>
		<!-- Version used for internal directory structure -->
		<hive.version.short>1.2.1</hive.version.short>
		<derby.version>10.10.1.1</derby.version>
		<parquet.version>1.7.0</parquet.version>
		<hive.parquet.version>1.6.0</hive.parquet.version>
		<jblas.version>1.2.4</jblas.version>
		<jetty.version>8.1.14.v20131031</jetty.version>
		<orbit.version>3.0.0.v201112011016</orbit.version>
		<chill.version>0.5.0</chill.version>
		<ivy.version>2.4.0</ivy.version>
		<oro.version>2.0.8</oro.version>
		<codahale.metrics.version>3.1.2</codahale.metrics.version>
		<avro.version>1.7.7</avro.version>
		<avro.mapred.classifier>hadoop2</avro.mapred.classifier>
		<jets3t.version>0.7.1</jets3t.version>
		<aws.java.sdk.version>1.9.16</aws.java.sdk.version>
		<aws.kinesis.client.version>1.3.0</aws.kinesis.client.version>
		<!-- org.apache.httpcomponents/httpclient -->
		<commons.httpclient.version>4.3.2</commons.httpclient.version>
		<!-- commons-httpclient/commons-httpclient -->
		<httpclient.classic.version>3.1</httpclient.classic.version>
		<commons.math3.version>3.4.1</commons.math3.version>
		<scala.version>2.10</scala.version>
		<scala.binary.version>2.10</scala.binary.version>
		<jline.version>${scala.version}</jline.version>
		<jline.groupid>org.scala-lang</jline.groupid>
		<codehaus.jackson.version>1.9.13</codehaus.jackson.version>
		<fasterxml.jackson.version>2.4.4</fasterxml.jackson.version>
		<snappy.version>1.1.1.7</snappy.version>
		<netlib.java.version>1.1.2</netlib.java.version>
		<calcite.version>1.2.0-incubating</calcite.version>
		<commons-codec.version>1.10</commons-codec.version>
		<!-- org.apache.commons/commons-lang/ -->
		<commons-lang2.version>2.6</commons-lang2.version>
		<!-- org.apache.commons/commons-lang3/ -->
		<commons-lang3.version>3.3.2</commons-lang3.version>
		<datanucleus-core.version>3.2.10</datanucleus-core.version>
		<janino.version>2.7.8</janino.version>
		<jersey.version>1.9</jersey.version>
		<joda.version>2.5</joda.version>
		<jodd.version>3.5.2</jodd.version>
		<jsr305.version>1.3.9</jsr305.version>
		<libthrift.version>0.9.2</libthrift.version>

		<test.java.home>${java.home}</test.java.home>
		<test.exclude.tags></test.exclude.tags>

		<!-- Dependency scopes that can be overridden by enabling certain profiles. 
			These profiles are declared in the projects that build assemblies. For other 
			projects the scope should remain as "compile", otherwise they are not available 
			during compilation if the dependency is transivite (e.g. "bagel/" depending 
			on "core/" and needing Hadoop classes in the classpath to compile). -->
		<flume.deps.scope>compile</flume.deps.scope>
		<hadoop.deps.scope>compile</hadoop.deps.scope>
		<hbase.deps.scope>compile</hbase.deps.scope>
		<hive.deps.scope>compile</hive.deps.scope>
		<parquet.deps.scope>compile</parquet.deps.scope>
		<parquet.test.deps.scope>test</parquet.test.deps.scope>

		<!-- Overridable test home. So that you can call individual pom files directly 
			without things breaking. -->
		<spark.test.home>${session.executionRootDirectory}</spark.test.home>

		<PermGen>64m</PermGen>
		<MaxPermGen>512m</MaxPermGen>
		<CodeCacheSize>512m</CodeCacheSize>
	</properties>
	<repositories>
		<repository>
			<id>scala-tools.org</id>
			<name>Scala-tools Maven2 Repository</name>
			<url>http://scala-tools.org/repo-releases</url>
		</repository>
	</repositories>
	<pluginRepositories>
		<pluginRepository>
			<id>scala-tools.org</id>
			<name>Scala-tools Maven2 Repository</name>
			<url>http://scala-tools.org/repo-releases</url>
		</pluginRepository>
	</pluginRepositories>

	<dependencies>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-core_${scala.binary.version}</artifactId>
			<version>${project.version}</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming_${scala.binary.version}</artifactId>
			<version>${project.version}</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-mllib_${scala.binary.version}</artifactId>
			<version>${project.version}</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-bagel_${scala.binary.version}</artifactId>
			<version>${project.version}</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-hive_${scala.binary.version}</artifactId>
			<version>${project.version}</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-graphx_${scala.binary.version}</artifactId>
			<version>${project.version}</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>com.github.scopt</groupId>
			<artifactId>scopt_${scala.binary.version}</artifactId>
			<version>3.2.0</version>
		</dependency>
		<dependency>
			<groupId>org.scala-lang</groupId>
			<artifactId>scala-library</artifactId>
			<version>2.10.5</version>
		</dependency>
		<dependency>
			<groupId>com.google.code.findbugs</groupId>
			<artifactId>jsr305</artifactId>
			<version>2.0.2</version>
		</dependency>
    <dependency>
            <groupId>org.kamranzafar</groupId>
            <artifactId>jtar</artifactId>
            <version>2.3</version>
    </dependency>
	</dependencies>
	<build>
		<plugins>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-dependency-plugin</artifactId>
				<version>2.10</version>
				<executions>
					<execution>
						<id>copy-dependencies</id>
						<phase>package</phase>
						<goals>
							<goal>copy-dependencies</goal>
						</goals>
						<configuration>
							<outputDirectory>${project.build.directory}/lib</outputDirectory>
							<overWriteReleases>false</overWriteReleases>
							<overWriteSnapshots>false</overWriteSnapshots>
							<overWriteIfNewer>true</overWriteIfNewer>
							<silent>true</silent>
							<excludeGroupIds>org.apache.hadoop,org.apache.hbase</excludeGroupIds>
						</configuration>
					</execution>
				</executions>
			</plugin>
			<plugin>
				<groupId>org.scala-tools</groupId>
				<artifactId>maven-scala-plugin</artifactId>
				<version>2.11</version>
				<executions>

					<execution>
						<id>compile</id>
						<goals>
							<goal>compile</goal>
						</goals>
						<phase>compile</phase>
					</execution>
					<execution>
						<id>test-compile</id>
						<goals>
							<goal>testCompile</goal>
						</goals>
						<phase>test-compile</phase>
					</execution>
					<execution>
						<phase>process-resources</phase>
						<goals>
							<goal>compile</goal>
						</goals>
					</execution>
				</executions>
			</plugin>
			<plugin>
				<artifactId>maven-compiler-plugin</artifactId>
				<configuration>
					<source>1.5</source>
					<target>1.5</target>
				</configuration>
			</plugin>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-shade-plugin</artifactId>
				<configuration>
					<shadedArtifactAttached>false</shadedArtifactAttached>
					<artifactSet>
						<includes>
							<!-- At a minimum we must include this to force effective pom generation -->
							<include>org.spark-project.spark:unused</include>

							<include>org.eclipse.jetty:jetty-io</include>
							<include>org.eclipse.jetty:jetty-http</include>
							<include>org.eclipse.jetty:jetty-continuation</include>
							<include>org.eclipse.jetty:jetty-servlet</include>
							<include>org.eclipse.jetty:jetty-plus</include>
							<include>org.eclipse.jetty:jetty-security</include>
							<include>org.eclipse.jetty:jetty-util</include>
							<include>org.eclipse.jetty:jetty-server</include>
							<include>tl.lin:lintools-datatypes</include>
							<include>edu.umd:cloud9</include>
							<include>com.google.guava:guava</include>
						</includes>
					</artifactSet>
					<relocations>
						<relocation>
							<pattern>org.eclipse.jetty</pattern>
							<shadedPattern>org.spark-project.jetty</shadedPattern>
							<includes>
								<include>org.eclipse.jetty.**</include>
							</includes>
						</relocation>
						<relocation>
							<pattern>com.google.common</pattern>
							<shadedPattern>org.spark-project.guava</shadedPattern>
							<excludes>
								<!-- These classes cannot be relocated, because the Java API exposes 
									the "Optional" type; the others are referenced by the Optional class. -->
								<exclude>com/google/common/base/Absent*</exclude>
								<exclude>com/google/common/base/Function</exclude>
								<exclude>com/google/common/base/Optional*</exclude>
								<exclude>com/google/common/base/Present*</exclude>
								<exclude>com/google/common/base/Supplier</exclude>
							</excludes>
						</relocation>
					</relocations>
				</configuration>
				<executions>
					<execution>
						<phase>package</phase>
						<goals>
							<goal>shade</goal>
						</goals>
					</execution>
				</executions>
			</plugin>
			<plugin>
				<groupId>org.codehaus.mojo</groupId>
				<artifactId>build-helper-maven-plugin</artifactId>
				<executions>
					<execution>
						<id>add-source</id>
						<phase>generate-sources</phase>
						<goals>
							<goal>add-source</goal>
						</goals>
						<configuration>
							<sources>
								<source>src/main/scala</source>
							</sources>
						</configuration>
					</execution>
					<execution>
						<id>add-test-source</id>
						<phase>generate-sources</phase>
						<goals>
							<goal>add-test-source</goal>
						</goals>
						<configuration>
							<sources>
								<source>src/test/scala</source>
							</sources>
						</configuration>
					</execution>
				</executions>
			</plugin>

			<plugin>
				<groupId>org.scala-tools</groupId>
				<artifactId>maven-scala-plugin</artifactId>

				<executions>
					<execution>
						<id>compile</id>
						<goals>
							<goal>compile</goal>
						</goals>
						<phase>compile</phase>
					</execution>

					<execution>
						<id>test-compile</id>
						<goals>
							<goal>testCompile</goal>
						</goals>
						<phase>test-compile</phase>
					</execution>

					<execution>
						<phase>process-resources</phase>
						<goals>
							<goal>compile</goal>
						</goals>
					</execution>
				</executions>
			</plugin>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-deploy-plugin</artifactId>
				<configuration>
					<skip>true</skip>
				</configuration>
			</plugin>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-install-plugin</artifactId>
				<configuration>
					<skip>true</skip>
				</configuration>
			</plugin>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-compiler-plugin</artifactId>
				<version>3.3</version>
				<configuration>
					<source>1.7</source>
					<target>1.7</target>
				</configuration>
			</plugin>
		</plugins>
	</build>
	<profiles>
		<profile>
			<id>kinesis-asl</id>
			<dependencies>
				<dependency>
					<groupId>org.apache.spark</groupId>
					<artifactId>spark-streaming-kinesis-asl_${scala.binary.version}</artifactId>
					<version>${project.version}</version>
				</dependency>
			</dependencies>
		</profile>

		<!-- Profiles that disable inclusion of certain dependencies. -->
		<profile>
			<id>flume-provided</id>
			<properties>
				<flume.deps.scope>provided</flume.deps.scope>
			</properties>
		</profile>
		<profile>
			<id>hadoop-provided</id>
			<properties>
				<hadoop.deps.scope>provided</hadoop.deps.scope>
			</properties>
		</profile>
		<profile>
			<id>hbase-provided</id>
			<properties>
				<hbase.deps.scope>provided</hbase.deps.scope>
			</properties>
		</profile>
		<profile>
			<id>hive-provided</id>
			<properties>
				<hive.deps.scope>provided</hive.deps.scope>
			</properties>
		</profile>
		<profile>
			<id>parquet-provided</id>
			<properties>
				<parquet.deps.scope>provided</parquet.deps.scope>
			</properties>
		</profile>
	</profiles>
</project>
